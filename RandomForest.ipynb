{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv(\"SMSSpamCollection\", sep='\\t')\n",
    "data.columns = ['label', 'body_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3) * 100\n",
    "\n",
    "data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8097</th>\n",
       "      <th>8098</th>\n",
       "      <th>8099</th>\n",
       "      <th>8100</th>\n",
       "      <th>8101</th>\n",
       "      <th>8102</th>\n",
       "      <th>8103</th>\n",
       "      <th>8104</th>\n",
       "      <th>8105</th>\n",
       "      <th>8106</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%    0    1    2    3    4    5    6    7  ...  8097  8098  \\\n",
       "0        24    25.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1       128     4.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2        39    15.4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "3        49     4.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4       116     6.9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "   8099  8100  8101  8102  8103  8104  8105  8106  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 8109 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "\n",
    "X_features = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
    "X_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_check_n_features', '_estimator_type', '_get_param_names', '_get_tags', '_make_estimator', '_more_tags', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_required_parameters', '_set_oob_score', '_validate_X_predict', '_validate_data', '_validate_estimator', '_validate_y_class_weight', 'apply', 'decision_path', 'feature_importances_', 'fit', 'get_params', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_params']\n"
     ]
    }
   ],
   "source": [
    "print(dir(RandomForestClassifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97668161, 0.97666068, 0.97396768, 0.96409336, 0.97307002])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "k_fold = KFold(n_splits=5)\n",
    "cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, max_depth=20, n_jobs=-1)\n",
    "rf_model = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.050705260696725624, 1804),\n",
       " (0.044561983170848724, 7353),\n",
       " (0.043362086830915594, 'body_len'),\n",
       " (0.03646690874332596, 3135),\n",
       " (0.028209216193123617, 4799),\n",
       " (0.02224669021235153, 2032),\n",
       " (0.018475540139560886, 5991),\n",
       " (0.01758479431756765, 6288),\n",
       " (0.017374060509245025, 1361),\n",
       " (0.0145274253894216, 6749)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf_model.feature_importances_, X_train.columns), reverse=True)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 / Recall: 0.591 / Accuracy: 0.942\n"
     ]
    }
   ],
   "source": [
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3), round(recall, 3), round((y_pred==y_test).sum() / len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, data['label'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RF(n_est, depth):\n",
    "    rf = RandomForestClassifier(n_estimators = n_est, max_depth=depth, n_jobs=-1)\n",
    "    rf_model = rf.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "    print('Est: {} / Depth: {} ----- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "        n_est, depth, round(precision, 3), round(recall,3),\n",
    "        round((y_pred==y_test).sum() / len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 10 / Depth: 10 ----- Precision: 1.0 / Recall: 0.308 / Accuracy: 0.909\n",
      "Est: 10 / Depth: 20 ----- Precision: 1.0 / Recall: 0.623 / Accuracy: 0.951\n",
      "Est: 10 / Depth: 30 ----- Precision: 0.981 / Recall: 0.719 / Accuracy: 0.961\n",
      "Est: 10 / Depth: None ----- Precision: 1.0 / Recall: 0.753 / Accuracy: 0.968\n",
      "Est: 50 / Depth: 10 ----- Precision: 1.0 / Recall: 0.24 / Accuracy: 0.9\n",
      "Est: 50 / Depth: 20 ----- Precision: 1.0 / Recall: 0.589 / Accuracy: 0.946\n",
      "Est: 50 / Depth: 30 ----- Precision: 1.0 / Recall: 0.644 / Accuracy: 0.953\n",
      "Est: 50 / Depth: None ----- Precision: 1.0 / Recall: 0.795 / Accuracy: 0.973\n",
      "Est: 100 / Depth: 10 ----- Precision: 1.0 / Recall: 0.185 / Accuracy: 0.893\n",
      "Est: 100 / Depth: 20 ----- Precision: 1.0 / Recall: 0.562 / Accuracy: 0.943\n",
      "Est: 100 / Depth: 30 ----- Precision: 1.0 / Recall: 0.651 / Accuracy: 0.954\n",
      "Est: 100 / Depth: None ----- Precision: 1.0 / Recall: 0.774 / Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "for n_est in [10, 50, 100]:\n",
    "    for depth in [10, 20, 30, None]:\n",
    "        train_RF(n_est, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Random Forest Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "X_tfidf_feat = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_tfidf.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8097</th>\n",
       "      <th>8098</th>\n",
       "      <th>8099</th>\n",
       "      <th>8100</th>\n",
       "      <th>8101</th>\n",
       "      <th>8102</th>\n",
       "      <th>8103</th>\n",
       "      <th>8104</th>\n",
       "      <th>8105</th>\n",
       "      <th>8106</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%  0  1  2  3  4  5  6  7  ...  8097  8098  8099  8100  \\\n",
       "0        24    25.0  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "1       128     4.7  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "2        39    15.4  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "3        49     4.1  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "4       116     6.9  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "\n",
       "   8101  8102  8103  8104  8105  8106  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 8109 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer=clean_text)\n",
    "X_count = count_vect.fit_transform(data['body_text'])\n",
    "X_count_feat = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_count.toarray())], axis=1)\n",
    "\n",
    "X_count_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>81.073345</td>\n",
       "      <td>8.692352</td>\n",
       "      <td>1.691046</td>\n",
       "      <td>1.694966</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.970377</td>\n",
       "      <td>0.972172</td>\n",
       "      <td>0.974331</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>85.562669</td>\n",
       "      <td>26.234260</td>\n",
       "      <td>0.415009</td>\n",
       "      <td>0.041678</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.973792</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>106.000853</td>\n",
       "      <td>17.393676</td>\n",
       "      <td>1.943905</td>\n",
       "      <td>0.882483</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.973433</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53.320802</td>\n",
       "      <td>20.461331</td>\n",
       "      <td>1.521435</td>\n",
       "      <td>1.364875</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.965889</td>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.972715</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.552154</td>\n",
       "      <td>21.509867</td>\n",
       "      <td>2.018187</td>\n",
       "      <td>1.494016</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.966786</td>\n",
       "      <td>0.967684</td>\n",
       "      <td>0.972176</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7       81.073345      8.692352         1.691046        1.694966   \n",
       "11      85.562669     26.234260         0.415009        0.041678   \n",
       "8      106.000853     17.393676         1.943905        0.882483   \n",
       "10      53.320802     20.461331         1.521435        1.364875   \n",
       "5       90.552154     21.509867         2.018187        1.494016   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "7               90                150   \n",
       "11            None                300   \n",
       "8               90                300   \n",
       "10            None                150   \n",
       "5               60                300   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.975785   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.975785   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.977578   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.977578   \n",
       "5     {'max_depth': 60, 'n_estimators': 300}           0.977578   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7            0.977558           0.975763           0.970377   \n",
       "11           0.978456           0.973968           0.969479   \n",
       "8            0.975763           0.974865           0.969479   \n",
       "10           0.977558           0.973070           0.965889   \n",
       "5            0.973968           0.974865           0.966786   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7            0.972172         0.974331        0.002641                1  \n",
       "11           0.971275         0.973792        0.003184                2  \n",
       "8            0.969479         0.973433        0.003344                3  \n",
       "10           0.969479         0.972715        0.004567                4  \n",
       "5            0.967684         0.972176        0.004216                5  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 150, 300],\n",
    "         'max_depth': [30, 60, 90, None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_tfidf_feat, data['label'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending = False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>71.896816</td>\n",
       "      <td>14.403747</td>\n",
       "      <td>1.076919</td>\n",
       "      <td>0.830002</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.970377</td>\n",
       "      <td>0.968582</td>\n",
       "      <td>0.973074</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>66.520901</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.586031</td>\n",
       "      <td>0.029420</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.968582</td>\n",
       "      <td>0.968582</td>\n",
       "      <td>0.972895</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.080130</td>\n",
       "      <td>5.108772</td>\n",
       "      <td>0.393150</td>\n",
       "      <td>0.061268</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.970377</td>\n",
       "      <td>0.968582</td>\n",
       "      <td>0.972715</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34.155736</td>\n",
       "      <td>0.347949</td>\n",
       "      <td>0.404318</td>\n",
       "      <td>0.054673</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.970377</td>\n",
       "      <td>0.967684</td>\n",
       "      <td>0.972715</td>\n",
       "      <td>0.003624</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.999505</td>\n",
       "      <td>0.376613</td>\n",
       "      <td>0.288827</td>\n",
       "      <td>0.112069</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 10}</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.964991</td>\n",
       "      <td>0.964093</td>\n",
       "      <td>0.971638</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "11      71.896816     14.403747         1.076919        0.830002   \n",
       "8       66.520901      0.240643         0.586031        0.029420   \n",
       "10      36.080130      5.108772         0.393150        0.061268   \n",
       "7       34.155736      0.347949         0.404318        0.054673   \n",
       "6        3.999505      0.376613         0.288827        0.112069   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "11            None                300   \n",
       "8               90                300   \n",
       "10            None                150   \n",
       "7               90                150   \n",
       "6               90                 10   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.976682   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.977578   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.976682   \n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.978475   \n",
       "6      {'max_depth': 90, 'n_estimators': 10}           0.975785   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "11           0.975763           0.973968           0.970377   \n",
       "8            0.975763           0.973968           0.968582   \n",
       "10           0.973968           0.973968           0.970377   \n",
       "7            0.973968           0.973070           0.970377   \n",
       "6            0.977558           0.975763           0.964991   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "11           0.968582         0.973074        0.003114                1  \n",
       "8            0.968582         0.972895        0.003702                2  \n",
       "10           0.968582         0.972715        0.002878                3  \n",
       "7            0.967684         0.972715        0.003624                4  \n",
       "6            0.964093         0.971638        0.005837                5  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 150, 300],\n",
    "         'max_depth': [30, 60, 90, None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_count_feat, data['label'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending = False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_SUPPORTED_LOSS', '__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_check_initialized', '_check_n_features', '_check_params', '_clear_state', '_compute_partial_dependence_recursion', '_estimator_type', '_fit_stage', '_fit_stages', '_get_param_names', '_get_tags', '_init_state', '_is_initialized', '_make_estimator', '_more_tags', '_raw_predict', '_raw_predict_init', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_required_parameters', '_resize_state', '_staged_raw_predict', '_validate_data', '_validate_estimator', '_validate_y', 'apply', 'decision_function', 'feature_importances_', 'fit', 'get_params', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_params', 'staged_decision_function', 'staged_predict', 'staged_predict_proba']\n"
     ]
    }
   ],
   "source": [
    "print(dir(GradientBoostingClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GB(est, max_depth, lr):\n",
    "    gb = GradientBoostingClassifier(n_estimators=est, max_depth=max_depth, learning_rate=lr)\n",
    "    gb_model = gb.fit(X_train, y_train)\n",
    "    y_pred = gb_model.predict(X_test)\n",
    "    precision, recall, fscore, train_support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "    print('Est: {} / Depth: {} / LR: {} ----- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "            est, max_depth, lr, round(precision, 3), round(recall, 3),\n",
    "            round((y_pred == y_test).sum()/len(y_pred), 3 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 50 / Depth: 3 / LR: 0.01 ----- Precision: 0.0 / Recall: 0.0 / Accuracy: 0.871\n",
      "Est: 50 / Depth: 3 / LR: 0.1 ----- Precision: 0.944 / Recall: 0.708 / Accuracy: 0.957\n",
      "Est: 50 / Depth: 3 / LR: 1 ----- Precision: 0.872 / Recall: 0.757 / Accuracy: 0.954\n",
      "Est: 50 / Depth: 7 / LR: 0.01 ----- Precision: 0.0 / Recall: 0.0 / Accuracy: 0.87\n",
      "Est: 50 / Depth: 7 / LR: 0.1 ----- Precision: 0.928 / Recall: 0.806 / Accuracy: 0.967\n",
      "Est: 50 / Depth: 7 / LR: 1 ----- Precision: 0.926 / Recall: 0.785 / Accuracy: 0.964\n",
      "Est: 50 / Depth: 11 / LR: 0.01 ----- Precision: 1.0 / Recall: 0.007 / Accuracy: 0.872\n",
      "Est: 50 / Depth: 11 / LR: 0.1 ----- Precision: 0.921 / Recall: 0.806 / Accuracy: 0.966\n",
      "Est: 50 / Depth: 11 / LR: 1 ----- Precision: 0.943 / Recall: 0.799 / Accuracy: 0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 50 / Depth: 15 / LR: 0.01 ----- Precision: 0.0 / Recall: 0.0 / Accuracy: 0.871\n",
      "Est: 50 / Depth: 15 / LR: 0.1 ----- Precision: 0.907 / Recall: 0.812 / Accuracy: 0.965\n",
      "Est: 50 / Depth: 15 / LR: 1 ----- Precision: 0.929 / Recall: 0.819 / Accuracy: 0.969\n",
      "Est: 100 / Depth: 3 / LR: 0.01 ----- Precision: 0.933 / Recall: 0.486 / Accuracy: 0.929\n",
      "Est: 100 / Depth: 3 / LR: 0.1 ----- Precision: 0.958 / Recall: 0.785 / Accuracy: 0.968\n",
      "Est: 100 / Depth: 3 / LR: 1 ----- Precision: 0.869 / Recall: 0.736 / Accuracy: 0.952\n",
      "Est: 100 / Depth: 7 / LR: 0.01 ----- Precision: 0.97 / Recall: 0.667 / Accuracy: 0.954\n",
      "Est: 100 / Depth: 7 / LR: 0.1 ----- Precision: 0.93 / Recall: 0.833 / Accuracy: 0.97\n",
      "Est: 100 / Depth: 7 / LR: 1 ----- Precision: 0.92 / Recall: 0.799 / Accuracy: 0.965\n",
      "Est: 100 / Depth: 11 / LR: 0.01 ----- Precision: 0.964 / Recall: 0.736 / Accuracy: 0.962\n",
      "Est: 100 / Depth: 11 / LR: 0.1 ----- Precision: 0.922 / Recall: 0.819 / Accuracy: 0.968\n",
      "Est: 100 / Depth: 11 / LR: 1 ----- Precision: 0.944 / Recall: 0.812 / Accuracy: 0.97\n",
      "Est: 100 / Depth: 15 / LR: 0.01 ----- Precision: 0.947 / Recall: 0.75 / Accuracy: 0.962\n",
      "Est: 100 / Depth: 15 / LR: 0.1 ----- Precision: 0.922 / Recall: 0.826 / Accuracy: 0.969\n",
      "Est: 100 / Depth: 15 / LR: 1 ----- Precision: 0.959 / Recall: 0.819 / Accuracy: 0.972\n",
      "Est: 150 / Depth: 3 / LR: 0.01 ----- Precision: 0.936 / Recall: 0.507 / Accuracy: 0.932\n",
      "Est: 150 / Depth: 3 / LR: 0.1 ----- Precision: 0.96 / Recall: 0.826 / Accuracy: 0.973\n",
      "Est: 150 / Depth: 3 / LR: 1 ----- Precision: 0.883 / Recall: 0.736 / Accuracy: 0.953\n",
      "Est: 150 / Depth: 7 / LR: 0.01 ----- Precision: 0.962 / Recall: 0.708 / Accuracy: 0.959\n",
      "Est: 150 / Depth: 7 / LR: 0.1 ----- Precision: 0.938 / Recall: 0.833 / Accuracy: 0.971\n",
      "Est: 150 / Depth: 7 / LR: 1 ----- Precision: 0.912 / Recall: 0.792 / Accuracy: 0.963\n",
      "Est: 150 / Depth: 11 / LR: 0.01 ----- Precision: 0.948 / Recall: 0.757 / Accuracy: 0.963\n",
      "Est: 150 / Depth: 11 / LR: 0.1 ----- Precision: 0.922 / Recall: 0.826 / Accuracy: 0.969\n",
      "Est: 150 / Depth: 11 / LR: 1 ----- Precision: 0.944 / Recall: 0.819 / Accuracy: 0.97\n",
      "Est: 150 / Depth: 15 / LR: 0.01 ----- Precision: 0.94 / Recall: 0.757 / Accuracy: 0.962\n",
      "Est: 150 / Depth: 15 / LR: 0.1 ----- Precision: 0.923 / Recall: 0.833 / Accuracy: 0.97\n",
      "Est: 150 / Depth: 15 / LR: 1 ----- Precision: 0.937 / Recall: 0.826 / Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "for n_est in [50, 100, 150]:\n",
    "    for max_depth in [3, 7, 11, 15]:\n",
    "        for lr in [0.01, 0.1, 1]:\n",
    "            train_GB(n_est, max_depth, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Settings with GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>413.632026</td>\n",
       "      <td>5.315942</td>\n",
       "      <td>0.491541</td>\n",
       "      <td>0.118583</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.963229</td>\n",
       "      <td>0.980251</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.968582</td>\n",
       "      <td>0.964991</td>\n",
       "      <td>0.969665</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>718.219414</td>\n",
       "      <td>118.051008</td>\n",
       "      <td>0.378388</td>\n",
       "      <td>0.119598</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.963229</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.967684</td>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.969486</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>404.595101</td>\n",
       "      <td>43.631406</td>\n",
       "      <td>2.281031</td>\n",
       "      <td>1.043162</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.965889</td>\n",
       "      <td>0.966786</td>\n",
       "      <td>0.969306</td>\n",
       "      <td>0.005147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>603.158547</td>\n",
       "      <td>4.455121</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.773433</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_est...</td>\n",
       "      <td>0.963229</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.972172</td>\n",
       "      <td>0.965889</td>\n",
       "      <td>0.965889</td>\n",
       "      <td>0.968947</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>476.486884</td>\n",
       "      <td>13.436054</td>\n",
       "      <td>1.001870</td>\n",
       "      <td>0.983848</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.967684</td>\n",
       "      <td>0.966786</td>\n",
       "      <td>0.967684</td>\n",
       "      <td>0.967870</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1     413.632026      5.315942         0.491541        0.118583   \n",
       "5     718.219414    118.051008         0.378388        0.119598   \n",
       "0     404.595101     43.631406         2.281031        1.043162   \n",
       "3     603.158547      4.455121         0.813333        0.773433   \n",
       "4     476.486884     13.436054         1.001870        0.983848   \n",
       "\n",
       "  param_learning_rate param_max_depth param_n_estimators  \\\n",
       "1                 0.1               7                150   \n",
       "5                 0.1              15                150   \n",
       "0                 0.1               7                100   \n",
       "3                 0.1              11                150   \n",
       "4                 0.1              15                100   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "1  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.963229   \n",
       "5  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.963229   \n",
       "0  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.964126   \n",
       "3  {'learning_rate': 0.1, 'max_depth': 11, 'n_est...           0.963229   \n",
       "4  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.964126   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "1           0.980251           0.971275           0.968582           0.964991   \n",
       "5           0.975763           0.971275           0.967684           0.969479   \n",
       "0           0.978456           0.971275           0.965889           0.966786   \n",
       "3           0.977558           0.972172           0.965889           0.965889   \n",
       "4           0.973070           0.967684           0.966786           0.967684   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "1         0.969665        0.005985                1  \n",
       "5         0.969486        0.004123                2  \n",
       "0         0.969306        0.005147                3  \n",
       "3         0.968947        0.005215                4  \n",
       "4         0.967870        0.002909                5  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "param = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [7, 11, 15],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(gb, param, cv=5, n_jobs=-1)\n",
    "cv_fit = clf.fit(X_tfidf_feat, data['label'])\n",
    "pd.DataFrame(cv_fit.cv_results_).sort_values('mean_test_score', ascending = False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>522.384134</td>\n",
       "      <td>23.446440</td>\n",
       "      <td>7.656829</td>\n",
       "      <td>12.561122</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_est...</td>\n",
       "      <td>0.965022</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.968582</td>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.970563</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>999.757030</td>\n",
       "      <td>117.913639</td>\n",
       "      <td>1.401895</td>\n",
       "      <td>1.447839</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.965919</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.966786</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.970383</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419.561394</td>\n",
       "      <td>8.999212</td>\n",
       "      <td>0.941082</td>\n",
       "      <td>0.865635</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.966816</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.966786</td>\n",
       "      <td>0.967684</td>\n",
       "      <td>0.970383</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>442.512306</td>\n",
       "      <td>10.013614</td>\n",
       "      <td>3.929738</td>\n",
       "      <td>4.181409</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.967684</td>\n",
       "      <td>0.967684</td>\n",
       "      <td>0.968582</td>\n",
       "      <td>0.968768</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202.411612</td>\n",
       "      <td>8.755448</td>\n",
       "      <td>0.863659</td>\n",
       "      <td>1.022643</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.966786</td>\n",
       "      <td>0.967684</td>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.968409</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5     522.384134     23.446440         7.656829       12.561122   \n",
       "8     999.757030    117.913639         1.401895        1.447839   \n",
       "2     419.561394      8.999212         0.941082        0.865635   \n",
       "7     442.512306     10.013614         3.929738        4.181409   \n",
       "6     202.411612      8.755448         0.863659        1.022643   \n",
       "\n",
       "  param_learning_rate param_max_depth param_n_estimators  \\\n",
       "5                 0.1              11                150   \n",
       "8                 0.1              15                150   \n",
       "2                 0.1               7                150   \n",
       "7                 0.1              15                100   \n",
       "6                 0.1              15                 50   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "5  {'learning_rate': 0.1, 'max_depth': 11, 'n_est...           0.965022   \n",
       "8  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.965919   \n",
       "2  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.966816   \n",
       "7  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.964126   \n",
       "6  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.964126   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "5           0.978456           0.968582           0.969479           0.971275   \n",
       "8           0.978456           0.969479           0.966786           0.971275   \n",
       "2           0.979354           0.971275           0.966786           0.967684   \n",
       "7           0.975763           0.967684           0.967684           0.968582   \n",
       "6           0.973968           0.966786           0.967684           0.969479   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "5         0.970563        0.004441                1  \n",
       "8         0.970383        0.004464                2  \n",
       "2         0.970383        0.004779                3  \n",
       "7         0.968768        0.003818                4  \n",
       "6         0.968409        0.003273                5  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "param = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [7, 11, 15],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(gb, param, cv=5, n_jobs=-1)\n",
    "cv_fit = clf.fit(X_count_feat, data['label'])\n",
    "pd.DataFrame(cv_fit.cv_results_).sort_values('mean_test_score', ascending = False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['body_text', 'body_len', 'punct%']], data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train['body_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf_vect_fit.transform(X_train['body_text'])\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test['body_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = pd.concat([X_train[['body_len', 'punct%']].reset_index(drop=True), \n",
    "                         pd.DataFrame(tfidf_train.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vect = pd.concat([X_test[['body_len', 'punct%']].reset_index(drop=True),\n",
    "                        pd.DataFrame(tfidf_test.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>7174</th>\n",
       "      <th>7175</th>\n",
       "      <th>7176</th>\n",
       "      <th>7177</th>\n",
       "      <th>7178</th>\n",
       "      <th>7179</th>\n",
       "      <th>7180</th>\n",
       "      <th>7181</th>\n",
       "      <th>7182</th>\n",
       "      <th>7183</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 7186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%    0    1    2    3    4    5    6    7  ...  7174  7175  \\\n",
       "0        43     4.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1       116     2.6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2        34    14.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "3        21     4.8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4        50     4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "   7176  7177  7178  7179  7180  7181  7182  7183  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 7186 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 / Recall: 0.82 / Accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\n",
    "\n",
    "rf_model = rf.fit(X_train_vect, y_train)\n",
    "y_pred = rf_model.predict(X_test_vect)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "        round(precision, 3), round(recall, 3), round((y_pred==y_test).sum() / len(y_pred), 3 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.951 / Recall: 0.839 / Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=150, max_depth=11)\n",
    "\n",
    "gb_model = gb.fit(X_train_vect, y_train)\n",
    "y_pred = gb_model.predict(X_test_vect)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "        round(precision, 3), round(recall, 3), round((y_pred==y_test).sum() / len(y_pred), 3 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
